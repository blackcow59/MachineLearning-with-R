install.packages("RWeka")
require(RWeka)
library(RWeka)
require(rJava)
library(RWeka)
require(RWeka)
subject_name <- c("John Doe", "Jane Doe", "Steve Graves")
temperature <- c(98.1, 98.6, 101.4)
flu_status <- c(F, F, T)
temperature[2]
temperature[2:3]
temperature[-2]
temperature[c(T, T, F)]
gender <- factor(c("MALE", "FEMALE", "MALE"))
gender
blood <- factor(c("O", "AB", "A"),
levels = c("A", "B", "AB", "O"))
blood
symptoms <- factor(c("SEVERE", "MILD", "MODERATE"),
levels = c("MILD", "MODERATE", "SEVERE"),
order = T)
symptoms
symptoms <- factor(c("SEVERE", "MILD", "MODERATE"),
levels = c("MILD", "MODERATE", "SEVERE"),
ordered = T)
symptoms
symptoms > "MODERATE"
subject_name[1]
temperature[1]
flu_status[1]
gender[1]
blood[1]
symptoms[1]
subject <- list(fullname = subject_name,
temperature = temperature,
flu_status = flu_status,
gender = gender,
blood = blood,
symptoms = symptoms)
subject
subject[2]
subject[[2]]
subject$temperature
subject[c("temperature", "flu_status")]
pt_data <- data.frame(subject_name, temperature, flu_status, gender, blood, symptoms)
pt_data
str(pt_data)
pt_data$subject_name
pt_data[c("temperture", "flu_status")]
pt_data[c("temperature", "flu_status")]
pt_data[2:3]
pt_data[1,2]
pt_data[c(1,3), c(2,4)]
pt_data[, 1]
pt_data[1,]
pt_data[ , ]
pt_data[c(1,3), c("temperature", "gender")]
pt_data[-2, c(-1, -3, -5, -6)]
pt_data$temp_c <- (pt_data$temperature - 32) *(5 / 9)
pt_data
pt_data[c("temperature", "tmep_C")]
pt_data[c("temperature", "tmep_c")]
pt_data[c("temperature", "temp_c")]
m <- matrix(c(1,2,3), nrow = 2)
m <- matrix(c(1,2,3,4 ), nrow = 2)
m
m <- matrix(c(1,2,3,4), ncol = 2)
m
m <- matrix(c(1,2,3,4,5,6), nrow = 2)
m
m <- matrix(c(1,2,3,4,5,6), ncol = 2)
m
m[1,1]
m[3,2]
m[1,]
m[,1]
save(x, y, z, file = "mydata.RData")
# ls() : 현재 메모리에 있는 데티어 구조의 목록 벡터를 반환한다.
ls()
# rm(객체) : 객체를 제거한다
rm(m, subject)
rm(list = ls())
# 데이터 탐색과 이해
# 데이터 특징과 예시를 탐색하고 데이터를 고유하게 만들어줄 특성을 알아본다.
usedcars <- read.csv("data/usedcars.csv")
usedcars
### 데이터 구조 탐색
str(usedcars)
### 수치 변수 탐색
summary(usedcars$year)
summary(usedcars[c("price", "mileage")])
# 중심 경향 측정 : 평균(mean)과 중앙값(median)
# 퍼짐 측정 : 사분위수와 다섯 숫자 요약 : 최솟값(min), 1사분위수(Q1), 중앙값(median), 3사분위수(Q3), 최댓값(max)
# 범위(range) : 최솟값과 최댓값 사이의 폭
range(usedcars$price)
diff(range(usedcars$price))
# 사분위 범위(IQR)
IQR(usedcars$price)
quantile(usedcars$price)
quantile(usedcars$price, probs = c(0.01, 0.99))
quantile(usedcars$price, seq(from = 0, to = 1, by = 0.2))
# 수치 변수 시각화 : 상자 그림(boxplot)
boxplot(usedcars$price, main = "Boxplot of Used Car Prices")
# 수치 변수 시각화 : 상자 그림(boxplot)
boxplot(usedcars$price, main = "Boxplot of Used Car Prices", ylab = "Price ($)")
boxplot(usedcars$mileage, main = "Boxplot of Used car Mileage", ylab = "Odometer (mi.)")
# 수치 변수 시각화 : 히스토그램(hist)
hist(usedcars$price, main = "Histogram of Used Car Prices", xlab = "Price ($)")
hist(usedcars$mileage, main = "Histogram of Used Car Mileage", xlab = "Odometer (mi.)")
hist(usedcars$mileage, main = "Histogram of Used Car Mileage", xlab = "Odometer (mi.)", breaks = 10)
hist(usedcars$mileage, main = "Histogram of Used Car Mileage", xlab = "Odometer (mi.)", breaks = 20)
hist(usedcars$mileage, main = "Histogram of Used Car Mileage", xlab = "Odometer (mi.)", breaks = 10)
hist(usedcars$mileage, main = "Histogram of Used Car Mileage", xlab = "Odometer (mi.)", breaks = c(5000, 10000, 15000, 20000))
hist(usedcars$mileage, main = "Histogram of Used Car Mileage", xlab = "Odometer (mi.)", breaks = c(5000, 10000, 15000, 20000, ...))
hist(usedcars$mileage, main = "Histogram of Used Car Mileage", xlab = "Odometer (mi.)", breaks = c(50000, 100000, 150000, 200000))
hist(usedcars$mileage, main = "Histogram of Used Car Mileage", xlab = "Odometer (mi.)", breaks = c(0, 50000, 100000, 150000, 200000))
# 수치 변수 시각화 : 히스토그램(hist)
hist(usedcars$price, main = "Histogram of Used Car Prices", xlab = "Price ($)")
# 퍼짐 측정 : 분산(var)과 표준편차(sd)
var(usedcars$price)
sd(usedcars$price)
var(usedcars$mileage)
sd(usedcars$mileage)
table(usedcars$year)
table(usedcars$model)
table(usedcars$color)
model_table <- table(usedcars$model)
prop.table(model_table)
round(prop.table(model_table), digits = 1)
color_table <- table(usedcars$color)
color_pct <- prop.table(color_table) *100
round(color_pct, digits = 1)
# 관계 시각화 : 산포도(산점도)
# 산포도(산점도) : 수치 특징 사이의 이변량 관계를 시각화하는 다이어그램
plot(price ~ mileage, data = usedcars,
main = "Scatterplot of Price vs. Mileage",
xlab = "Used Car Odometer (mi.)",
ylab = "Used Car Price ($)")
# 관계 관찰 : 이원 교차표
install.packages("gmodels")
# 관계 관찰 : 이원 교차표
# install.packages("gmodels")
require(gmodels)
usedcars$conservative <- usedcars$color %in% c("Black", "Gray", "Sliver", "White")
table(usedcars$conservative)
usedcars$conservative <- usedcars$color %in% c("Black", "Gray", "Silver", "White")
table(usedcars$conservative)
CrossTable(x = usedcars$model, y = usedcars$conservative)
CrossTable(x = usedcars$model, y = usedcars$conservative, chisq = T)
wbcd <- read.csv("data/wisc_bc_data.csv")
str(wbcd)
wbcd <- read.csv("data/wisc_bc_data.csv")
str(wbcd)
# id 변수는 단순히 데이터 내에서의 환자 아이디이기 때문에 유용한 정보를 제공하지 않으며 모델에서 제외할 필요가 있다.
# 머신러닝 방법에 상관없이 id변수는 항상 제외시켜야 한다.
wbcd <- wbcd[-1]
# diagnosis는 예측하려는 결과이므로 특별히 관심이 있다.
# 이 특징은 예시가 양성 종양인지 음성 종양인지 여부를 나타낸다
table(wbcd$diagnosis)
# 많은 R 머신러닝 분류기는 목표 특징이 팩터로 코딩돼야만 한다.
# 따라서 diagnosis변수를 다시 코드화 해야한다.
# 또한 labels파라미터를 이용해 "B"와 "M" 값에 유용한 정보를 주는 레이블을 제공할 것이다.
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B", "M"),
labels = c("Benign", "Malignant"))
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 1)
# 설명을 위해 남은 특징 중 세 개만 자세히 살펴보자.
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
## 변환 : 수치 데이터 정규화
normalize <- function(x) {
return((x - mean(x)) / (max(x) - min(x)))
}
normalize(c(1,2,3,4,5))
return((x - min(x)) / (max(x) - min(x)))
## 변환 : 수치 데이터 정규화
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
normalize(c(1,2,3,4,5))
normalize(c(10, 20, 30, 40, 50))
# lapply(list, function) : 리스트를 취해 각 리스트 항목에 지정된 함수를 적용한다.
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
summary(wbcd_n)
## 데이터 준비 : 훈련 및 테스트 데이터셋 생성
# 학습자가 레이블이 없는 데이터의 잡합에 대해 얼마나 잘 수행되는가?
# k-NN 모델을 구축하고자 사용되는 훈련 데이터셋과
# 모델의 예측 정확도를 평가하고자 사용되는 테스트 데이터셋
wbcd_train <- wbcd_n[1:469, ]
wbcd_test <- wbcd_n[470:569, ]
# k-NN모델을 훈련하고자 diagnosis를 팩터 벡터에 저장하고 훈려 데이터셋과 테스트 데이터셋으로 분리한다.
wbcd_train_labels <- wbcd[1:469, 1]
wbcd_test_labels <- wbcd[470:569, 1]
# 테스트 인스턴스를 분류하고자 분류를 위한 기본 R 함수를제공하는 class 패키지의 k-NN 구현을 사용할 것이다.
install.packages("class")
# 테스트 인스턴스를 분류하고자 분류를 위한 기본 R 함수를제공하는 class 패키지의 k-NN 구현을 사용할 것이다.
# install.packages("class")
require(class)
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 21)
# gmodels 패키지의 CrossTable() 함수 이용
require(gmodels)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq = F)
# 벡터를 표준화 하고자 R 내장함수 scale()을 이용해 기본 방식인 z-점수 표준화 방식으로 값을 재조정한다.
# scale() 함수는 데이터 프렝미에 직접 적용할 수 있으므로 lapply()함수를 사용할 필요가 없다.
wbcd_z <- as.data.frame(scale(wbcd[-1]))
summary(wbcd_z)
wbcd_train_z <- wbcd_z[1:469, ]
wbcd_test_z <- wbdcd_z[470:569, ]
wbcd_test_z <- wbcd_z[470:569, ]
wbcd_train_labels_z <- wbcd[1:469, 1]
wbcd_test_labels_z <- wbcd[470:569, 1]
wbcd_test_pred_z <- knn(train = wbcd_train_z, test = wbcd_test_z,
cl = wbcd_train_labels_z, k = 21)
CrossTable(x = wbcd_test_labels_z, y = wbcd_test_pred_z,
prop.chisq = F)
## k의 대체 값 테스트
wbcd_test_pred_21 <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 21)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred_21, prop.chisq = F)
wbcd_test_pred_1 <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 1)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred_1, prop.chisq = F)
# k = 5
wbcd_test_pred_5 <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 5)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred_5, prop.chisq = F)
# k = 11
wbcd_test_pred_11 <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 11)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred_11, prop.chisq = F)
# k = 15
wbcd_test_pred_15 <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 15)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred_15, prop.chisq = F)
# k = 27
wbcd_test_pred_27 <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 27)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred_27, prop.chisq = F)
